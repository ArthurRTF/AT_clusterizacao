{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78b1fbce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Means: ARI=0.073, NMI=0.321, Silhouette=0.003\n"
     ]
    }
   ],
   "source": [
    "# Questão 11\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score, silhouette_score\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# a\n",
    "dataset = fetch_20newsgroups(remove=(\"headers\", \"footers\", \"quotes\"))\n",
    "X_texts = dataset.data\n",
    "y       = dataset.target\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df=0.5, stop_words=\"english\")\n",
    "X_tfidf = vectorizer.fit_transform(X_texts)\n",
    "\n",
    "kmeans = KMeans(n_clusters=20, random_state=42)\n",
    "labels_kmeans = kmeans.fit_predict(X_tfidf)\n",
    "\n",
    "ari = adjusted_rand_score(y, labels_kmeans)\n",
    "nmi = normalized_mutual_info_score(y, labels_kmeans)\n",
    "sil = silhouette_score(X_tfidf, labels_kmeans, sample_size=1000)  \n",
    "\n",
    "print(f\"K-Means: ARI={ari:.3f}, NMI={nmi:.3f}, Silhouette={sil:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca6e8cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tópico 0: people, government, gun, law, right, guns, state, rights, crime, make\n",
      "Tópico 1: windows, dos, ms, version, running, os, microsoft, nt, drivers, driver\n",
      "Tópico 2: god, jesus, bible, believe, faith, christ, christian, christians, church, life\n",
      "Tópico 3: geb, dsl, chastity, n3jxp, cadre, pitt, shameful, intellect, skepticism, surrender\n",
      "Tópico 4: key, chip, encryption, clipper, keys, escrow, algorithm, government, secure, security\n",
      "Tópico 5: drive, scsi, ide, drives, disk, hard, controller, floppy, hd, cd\n",
      "Tópico 6: game, team, games, year, players, season, play, hockey, win, league\n",
      "Tópico 7: thanks, advance, hi, looking, mail, info, help, appreciated, appreciate, information\n",
      "Tópico 8: space, nasa, shuttle, launch, orbit, moon, earth, station, lunar, program\n",
      "Tópico 9: card, video, monitor, bus, vga, drivers, cards, driver, color, ati\n",
      "Tópico 10: armenian, armenians, turkish, genocide, armenia, turkey, turks, said, soviet, muslim\n",
      "Tópico 11: 00, 10, sale, 50, 20, shipping, 15, new, price, 25\n",
      "Tópico 12: window, motif, server, application, manager, display, problem, widget, screen, program\n",
      "Tópico 13: israel, israeli, jews, arab, arabs, lebanese, jewish, lebanon, peace, israelis\n",
      "Tópico 14: does, know, anybody, mean, doesn, appreciated, exist, let, don, info\n",
      "Tópico 15: just, don, like, think, ve, good, really, time, say, ll\n",
      "Tópico 16: car, bike, cars, engine, new, miles, dealer, good, insurance, price\n",
      "Tópico 17: edu, mail, com, list, address, send, email, mailing, cs, internet\n",
      "Tópico 18: file, files, program, ftp, directory, format, image, zip, gif, bmp\n",
      "Tópico 19: use, mac, software, apple, modem, port, memory, simms, printer, pc\n"
     ]
    }
   ],
   "source": [
    "# b\n",
    "nmf = NMF(n_components=20, random_state=42)\n",
    "W = nmf.fit_transform(X_tfidf)\n",
    "H = nmf.components_\n",
    "\n",
    "termos = vectorizer.get_feature_names_out()\n",
    "for i, topico in enumerate(H):\n",
    "    top_words = [termos[x] for x in topico.argsort()[-10:][::-1]]\n",
    "    print(f\"Tópico {i}: {', '.join(top_words)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9560c9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tópico 0: alomar, wins, __, baerga, park, _______, mars, adl, ____, _____\n",
      "Tópico 1: ax, ifas, ufl, gnv, arens, caps, _incredibly_, loopback, mywinobj, sigh\n",
      "Tópico 2: telix, kermit, vcr, catalog, olwm, adb, nutek, navy, allergic, tsk\n",
      "Tópico 3: deletion, ripem, slot, quicktime, lc, luke, pds, tt, adaptor, iisi\n",
      "Tópico 4: banks, pitt, geb, shameful, cadre, gordon, skepticism, intellect, chastity, n3jxp\n",
      "Tópico 5: god, jesus, armenian, turkish, christ, armenians, sin, islam, greek, heaven\n",
      "Tópico 6: mahan, tgv, ver, gainey, cornerstone, lm, washer, syquest, charley, main_win\n",
      "Tópico 7: lc, printers, ink, bj, deskjet, hernia, davewood, buyer, boulder, pages\n",
      "Tópico 8: murray, centaur, francis, gm, jagr, nixon, proton, kingman, db, finnish\n",
      "Tópico 9: sox, morris, champs, keller, sas, quakers, kkeller, ivy, male, upenn\n",
      "Tópico 10: vesa, helmet, eisa, vlb, cview, spacecraft, megs, captain, caps, switches\n",
      "Tópico 11: ditto, gl, wheelie, shaft, tires, rle, saab, corn, vgalogo, clinic\n",
      "Tópico 12: app, polygons, freewill, null, dsp, config, gcc, gc, bm, gxxor\n",
      "Tópico 13: just, like, know, don, people, think, does, use, thanks, good\n",
      "Tópico 14: projector, motto, cci, tempest, 336, grows, bait, radius, wk, 18084tm\n",
      "Tópico 15: azerbaijan, loser, villages, azerbaijani, cobb, hillary, stephanopoulos, karabakh, territory, lcd\n",
      "Tópico 16: cooling, c650, towers, deane, plants, colormaps, uranium, ncsl, nist, vax\n",
      "Tópico 17: female, hopper, patterns, acs, kratz, nanci, borland, expos, mcgill, propulsion\n",
      "Tópico 18: mom, soderstrom, mozumder, sanderson, rockets, lyme, advertising, torque, cpk, tire\n",
      "Tópico 19: __, xman, swiss, sharks, baku, ruins, stove, messenger, idiot, narrative\n"
     ]
    }
   ],
   "source": [
    "# c \n",
    "lda = LatentDirichletAllocation(n_components=20, random_state=42, learning_method=\"batch\")\n",
    "lda.fit(X_tfidf)\n",
    "\n",
    "for i, topico in enumerate(lda.components_):\n",
    "    top_words = [termos[x] for x in topico.argsort()[-10:][::-1]]\n",
    "    print(f\"Tópico {i}: {', '.join(top_words)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5479c175",
   "metadata": {},
   "source": [
    "Seguindo as etapas de:\n",
    "\n",
    "1.Pré-processamento -> conversão em vetores TF-IDF.\n",
    "\n",
    "2.Aplicação dos algoritmos (K-Means, NMF e LDA).\n",
    "\n",
    "3.Extração de palavras-chave por tópico (no caso de NMF e LDA).\n",
    "\n",
    "4.Avaliação da coerência dos tópicos com base na interpretabilidade.\n",
    "\n",
    "O K-Means foi aplicado sobre representações TF-IDF e permitiu explorar a segmentação textual, mas apresentou resultados limitados devido à alta dimensionalidade e sobreposição dos dados.\n",
    "\n",
    "O NMF gerou tópicos semanticamente mais claros e interpretáveis, enquanto o LDA também identificou temas relevantes, mas com maior difusão entre termos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "infnet-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
